%% Design Lidar SLAM Algorithm Using Unreal Engine Simulation Environment

% evaluate a lidar perception algorithm using
% synthetic lidar data generated from the simulation environment. The
% example walks you through the following steps:
%
% * Record and visualize synthetic lidar sensor data from the simulation
% environment.
% * Develop a perception algorithm to build a map using SLAM in MATLAB(R).

%% Set Up Scenario in Simulation Environment

% First, set up a scenario in the simulation environment that can be
% used to test the perception algorithm. Use a scene depicting a typical
% city block with a single vehicle that is the vehicle under test. You can
% use this scene to test the performance of the algorithm in an urban road
% setting.

% Load reference path for recorded drive segment
xData   = load('refPosesX.mat');
yData   = load('refPosesY.mat');
yawData = load('refPosesT.mat');

% Set up workspace variables used by model
refPosesX = xData.refPosesX;
refPosesY = yData.refPosesY;
refPosesT = yawData.refPosesT;

% Display path on scene image
sceneName = 'USCityBlock';
hScene = figure;
helperShowSceneImage(sceneName);
hold on
scatter(refPosesX(:,2),refPosesY(:,2),7,'filled')

% Adjust axes limits
xlim([-150 100])
ylim([-125 75])

%%

close(hScene)

if ~ispc
    error(['3D Simulation is only supported on Microsoft',char(174),' Windows',char(174),'.']);
end

% Open the model
modelName = 'LidarSLAMIn3DSimulation';
open_system(modelName);
snapnow;

%%
% # Simulate the model to record synthetic lidar data generated by the
% sensor and save it to the workspace.
% # Use the sensor data saved to the workspace to develop a perception
% algorithm in MATLAB. The perception algorithm builds a map of the
% surroundings using SLAM.
% # Visualize the results of the built map.

%% Record and Visualize Synthetic Lidar Sensor Data

% Simulate the model. The streaming point cloud display shows the synthetic
% lidar sensor data. The scene display shows the synthetic INS sensor data.


% Update simulation stop time to end when reference path is completed
simStopTime = refPosesX(end,1);
set_param(gcs,'StopTime',num2str(simStopTime));

% Load INS data from MAT file
data = load('insMeasurement.mat');
insData = data.insMeasurement.signals.values;

% Run the simulation
simOut = sim(modelName);

% Create a pointCloud array from the recorded data
ptCloudArr = helperGetPointCloud(simOut);

%% Use Recorded Data to Develop Perception Algorithm
% The synthetic lidar sensor data can be used to develop, experiment with,
% and verify a perception algorithm in different scenarios. This example
% uses an algorithm to build a 3-D map of the environment from streaming
% lidar data. Such an algorithm is a building block for applications like
% localization. It can also be used to create high-definition (HD) maps for
% geographic regions that can then be used for online localization. T
% Such an algorithm is susceptible to drift while accumulating a map over
% long sequences. 
% This uses point cloud registration to accept or reject loop
% closure candidates and to find the loop closure transformation.

% Set the random seed for example reproducibility
rng(0);

% Create a lidar map builder
mapBuilder = helperLidarMapBuilder('DownsampleGridStep',0.25,'Verbose',true);

% Configure the map builder to detect loop closures
configureLoopDetector(mapBuilder,'LoopConfirmationRMSE',1.5, ...
    'SearchRadius',0.15,'DistanceThreshold',0.2);

% Loop through the point cloud array and progressively build a map
skipFrames = 10;
numFrames  = numel(ptCloudArr);
exitLoop   = false;

prevInsMeas = insData(1,:);
for n = 1:skipFrames:numFrames
    
    insMeas = insData(n,:);
    
    % Estimate initial transformation using INS
    initTform = helperEstimateRelativeTransformationFromINS(insMeas,prevInsMeas);
    
    % Update map with new lidar frame
    updateMap(mapBuilder,ptCloudArr(n),initTform);
    
    % Update top-view display
    isDisplayOpen = updateDisplay(mapBuilder,exitLoop);
    
    % Check and exit if needed
    exitLoop = ~isDisplayOpen;
    
    prevInsMeas = insMeas;
end

snapnow;

% Close display
closeDisplay = true;
updateDisplay(mapBuilder,closeDisplay);

%%
% The accumulated drift progressively increases over time.
% Once sufficient loop closures are detected, the accumulated drift can be
% corrected using pose graph optimization. 
% After the pose graph has been optimized, rebuild the map using the
% updated poses.
% Using |optimizeMapPoses| and |rebuildMap| to correct for the drift and
% rebuild the map. Visualize the view set before and after pose graph
% optimization.

% Visualize viewset before pose graph optimization
hFigViewset = figure;
hG = plot(mapBuilder.ViewSet);
view(hG.Parent,2);
title('Viewset Display')

% Get the estimated trajectory before pose graph optimization to evaluate
% its accuracy
estimatedTrajectoryBefore = vertcat(mapBuilder.ViewSet.Views.AbsolutePose.Translation);

% Optimize pose graph and rebuild map
optimizeMapPoses(mapBuilder);
rebuildMap(mapBuilder);

% Get the estimated trajectory after pose graph optimization to evaluate
% its accuracy
estimatedTrajectoryAfter = vertcat(mapBuilder.ViewSet.Views.AbsolutePose.Translation);

% Overlay viewset after pose graph optimization
hold(hG.Parent,'on');
plot(mapBuilder.ViewSet);
hold(hG.Parent,'off');

legend(hG.Parent,'before','after')

%%
% To evaluate the accuracy of the built map, compute the root-mean-square
% error (rmse) between the estimated trajectory and the ground truth
% trajectory before and after pose graph optimization.

groundTruthTrajectory = squeeze(simOut.lidarLocation.signals.values)';
selectedGroundTruth = groundTruthTrajectory(1:skipFrames:numFrames,:);

% Apply an offset since the estimated trajectory starts at [0 0 0] with an
% angular offset of 90 degrees in the z-axis.
offsetTform = rigidtform3d([0 0 90],selectedGroundTruth(1,:));
selectedGroundTruth = transformPointsInverse(offsetTform,selectedGroundTruth);

rmseBefore = rmse(selectedGroundTruth,estimatedTrajectoryBefore,"all");
disp(['rmse before pose graph optimization: ' num2str(rmseBefore)])

rmseAfter = rmse(selectedGroundTruth,estimatedTrajectoryAfter,"all");
disp(['rmse after pose graph optimization: ' num2str(rmseAfter)])

%%
% Visualize the accumulated point cloud map computed using the recorded
% data.

%close(hFigViewset)

hFigMap = figure;
pcshow(mapBuilder.Map)

% Customize axes labels and title
xlabel('X (m)')
ylabel('Y (m)')
zlabel('Z (m)')
title('Point Cloud Map')

helperMakeFigurePublishFriendly(hFigMap);

%%
% the perception algorithm can be
% stress-tested under different scenarios. This approach can be used to
% increase coverage for scenarios that are difficult to reproduce in the
% real world.

% Close windows
%close(hFigMap)
%close_system(modelName)

%% Supporting Functions
%%%
% *helperGetPointCloud* Extract an array of <docid:vision_ref#buphqma-1
% |pointCloud|> objects.
function ptCloudArr = helperGetPointCloud(simOut)

% Extract signal
ptCloudData = simOut.ptCloudData.signals.values;

% Create a pointCloud array
ptCloudArr = pointCloud(ptCloudData(:,:,:,1));

for n = 2 : size(ptCloudData,4)
    ptCloudArr(end+1) = pointCloud(ptCloudData(:,:,:,n));  %#ok<AGROW>
end
end

%%%
% *helperMakeFigurePublishFriendly* Adjust figure so that screenshot
% captured by publish is correct.
function helperMakeFigurePublishFriendly(hFig)

if ~isempty(hFig) && isvalid(hFig)
    hFig.HandleVisibility = 'callback';
end
end

%%%